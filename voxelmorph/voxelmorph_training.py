# -*- coding: utf-8 -*-
"""voxelmorph_training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LCgdzK7im-U5c1SzKFiVCIHjwSSqOxtB

Voxelmorph Training on 3-D volumes downsampled

# Setup
"""

!pip install voxelmorph 
!pip install --upgrade nibabel
!pip install nilearn

# imports
import os, sys

# third party imports
import numpy as np
import tensorflow as tf
assert tf.__version__.startswith('2.'), 'This tutorial assumes Tensorflow 2.0+'
print(tf.__version__)
import nibabel as nb
import nilearn as nl
import nilearn.image

# local imports
import voxelmorph as vxm
import neurite as ne
from tensorflow.keras.datasets import mnist

import time
import matplotlib.pyplot as plt
from glob import glob
import nibabel.processing as nbp

from google.colab import drive
drive.mount('/content/drive')

data_path = "/content/drive/My Drive/Image_Registration_Project/dataset_ants_resampled/Brain_extracted_Train/T1_BET_undersampled/"
os.chdir(data_path)
filelist = glob(os.path.join(data_path,'*'))
print(filelist)
print("Number of images in folder: {}".format(len(filelist)))

"""# Data Preprocessing"""

data_np = np.zeros(shape=(len(filelist), 128, 128, 128))
data_np.shape

target_shape = np.array((128,128,128))
new_resolution = [2,]*3
new_affine = np.zeros((4,4))
new_affine[:3,:3] = np.diag(new_resolution)
new_affine[:3,3] = target_shape*new_resolution/2.*-1
new_affine[3,3] = 1.

new_affine

image_list = []
img_shape = np.array((64, 64, 64))
for i in range(len(filelist)):
  file = filelist[i]
  #inp_nb = nb.load(file)
  inp_nb = nl.image.load_img(file)
  #interim_nb = inp_nb
  interim_nb = nl.image.resample_img(inp_nb, target_affine=new_affine, target_shape=target_shape, interpolation='nearest')
  # interim_nb = nbp.resample_from_to(from_img=inp_nb, to_vox_map=(img_shape, inp_nb.affine), order=3)
  #interim_nb = nbp.conform(from_img=inp_nb,out_shape=(64, 64, 64), voxel_size=(1.0, 1.0, 1.0), order=3, orientation="RAS")
  print("=========== voxel resolution, centre, affines, orientation and shape ===========")
  print("voxel resolution : {}".format(interim_nb.header["pixdim"][1:4]))
  print()
  print("Centre of the image: {}".format([float(interim_nb.header["qoffset_x"]), float(interim_nb.header["qoffset_y"]), float(interim_nb.header["qoffset_z"])]))
  print()
  print("Affine matrix: {}".format(nb.aff2axcodes(interim_nb.affine)))
  print()
  print("Orientation: {}".format(interim_nb.affine))
  print()
  print("Shape of the resampled image: {}".format(interim_nb.header.get_data_shape()))
  print()
  op_np = interim_nb.dataobj
  op_np = op_np/np.max(op_np)
  data_np[i,:,:,:] = op_np

  image_list.append(op_np)

image_list = []
img_shape = np.array((128, 128, 128))
for i in range(len(filelist)):
  file = filelist[i]
  #inp_nb = nb.load(file)
  inp_nb = nl.image.load_img(file)
  #interim_nb = inp_nb
  #interim_nb = nl.image.resample_img(inp_nb, target_affine=new_affine, target_shape=target_shape, interpolation='nearest')
  # interim_nb = nbp.resample_from_to(from_img=inp_nb, to_vox_map=(img_shape, inp_nb.affine), order=3)
  #interim_nb = nbp.conform(from_img=inp_nb,out_shape=(64, 64, 64), voxel_size=(1.0, 1.0, 1.0), order=3, orientation="RAS")
  print("=========== voxel resolution, centre, affines, orientation and shape ===========")
  print("voxel resolution : {}".format(inp_nb.header["pixdim"][1:4]))
  print()
  print("Centre of the image: {}".format([float(inp_nb.header["qoffset_x"]), float(inp_nb.header["qoffset_y"]), float(inp_nb.header["qoffset_z"])]))
  print()
  print("Affine matrix: {}".format(nb.aff2axcodes(inp_nb.affine)))
  print()
  print("Orientation: {}".format(inp_nb.affine))
  print()
  print("Shape of the resampled image: {}".format(inp_nb.header.get_data_shape()))
  print()
  op_np = inp_nb.dataobj
  final_dim = op_np.shape[2]
  tails = int((128.0 - final_dim)//2)
  left_tail = tails
  right_tail = 128-tails
  print(tails)
  op_np = op_np/np.max(op_np)
  data_np[i,:,:,0:final_dim] = op_np

  image_list.append(op_np)

print(data_np[7,64,:,:])
data_np.shape

def vxm_data_generator(x_data, batch_size=32):
    """
    Generator that takes in data of size [N, H, W], and yields data for
    our custom vxm model. Note that we need to provide numpy data for each
    input, and each output.

    inputs:  moving [bs, H, W, 1], fixed image [bs, H, W, 1]
    outputs: moved image [bs, H, W, 1], zero-gradient [bs, H, W, 2]
    """

    # preliminary sizing
    vol_shape = x_data.shape[1:] # extract data shape
    ndims = len(vol_shape)
    
    # prepare a zero array the size of the deformation
    # we'll explain this below
    zero_phi = np.zeros([batch_size, *vol_shape, ndims])
    
    while True:
        # prepare inputs:
        # images need to be of the size [batch_size, H, W, 1]
        idx1 = np.random.randint(0, x_data.shape[0], size=batch_size)
        moving_images = x_data[idx1, ..., np.newaxis]
        idx2 = np.random.randint(0, x_data.shape[0], size=batch_size)
        fixed_images = x_data[idx2, ..., np.newaxis]
        inputs = [moving_images, fixed_images]
        
        # prepare outputs (the 'true' moved image):
        # of course, we don't have this, but we know we want to compare 
        # the resulting moved image with the fixed image. 
        # we also wish to penalize the deformation field. 
        outputs = [fixed_images, zero_phi]
        
        yield (inputs, outputs)

train_generator = vxm_data_generator(data_np[:, :, :, :], batch_size=1)
train_in_sample, train_out_sample = next(train_generator)

# visualize
images = [img[0, :, 64, :, 0] for img in train_in_sample + train_out_sample]
titles = ['moving', 'fixed', 'moved ground-truth (fixed)', 'zeros']
ne.plot.slices(images, titles=titles, cmaps=['gray'], do_colorbars=True);

"""Validation generator"""

validation_generator = vxm_data_generator(data_np[10:16, :, :, :], batch_size=1)
val_in_sample, val_out_sample = next(validation_generator)

# visualize
images = [img[0, :, 64, :, 0] for img in val_in_sample + val_out_sample]
titles = ['moving', 'fixed', 'moved ground-truth (fixed)', 'zeros']
ne.plot.slices(images, titles=titles, cmaps=['gray'], do_colorbars=True);

"""# Model Building"""

nb_features = [[32, 32, 32, 32, 32], [32, 32, 32, 32, 32, 32, 16]]
vol_shape = data_np.shape[1:]
print("shape of volume: {}".format(vol_shape))
print("Filters in Unet: {}".format(nb_features))

# unet
vxm_model = vxm.networks.VxmDense(vol_shape, nb_features, int_steps=3)

# losses and loss weights
losses = [vxm.losses.NCC().loss, vxm.losses.Grad('l2').loss]
loss_weights = [1, 1]

vxm_model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4), loss=losses, loss_weights=loss_weights)

def plot_history(hist, loss_name='loss'):
    # Simple function to plot training history.
    plt.figure()
    plt.plot(hist.epoch, hist.history[loss_name], '.-')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.show()

"""# Training Model"""

hist = vxm_model.fit_generator(train_generator, epochs=30, steps_per_epoch=5, verbose=2);

# as before, let's visualize what happened
plot_history(hist)

"""# Validation and Prediction"""

# prediction
val_pred = vxm_model.predict(val_in_sample)

mynb_np1 = train_in_sample[0][0,:,:,:, 0]
mynb_np2 = train_in_sample[1][0,:,:,:, 0]

mid_slices_fixed = [np.take(mynb_np2, 55, axis=d) for d in range(3)]
mid_slices_fixed[1] = np.rot90(mid_slices_fixed[1], 1)
mid_slices_fixed[2] = np.rot90(mid_slices_fixed[2], -1)

mid_slices_moving = [np.take(mynb_np1, 55, axis=d) for d in range(3)]
mid_slices_moving[1] = np.rot90(mid_slices_moving[1], 1)
mid_slices_moving[2] = np.rot90(mid_slices_moving[2], -1)

mid_slices_pred = [np.take(val_pred[0][0, :, :, :, 0], 55, axis=d) for d in range(3)]
mid_slices_pred[1] = np.rot90(mid_slices_pred[1], 1)
mid_slices_pred[2] = np.rot90(mid_slices_pred[2], -1)
ne.plot.slices(mid_slices_fixed + mid_slices_moving + mid_slices_pred, cmaps=['gray'], do_colorbars=True, grid=[3,3]);

# visualize registration
images = [img[0, 45, :, :, 0] for img in train_in_sample + val_pred] 
titles = ['moving', 'fixed', 'moved', 'flow']
ne.plot.slices(images, titles=titles, cmaps=['gray'], do_colorbars=True);

flow = val_pred[1].squeeze()
ne.plot.flow([flow], width=5);